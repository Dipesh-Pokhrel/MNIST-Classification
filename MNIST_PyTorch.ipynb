{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_PyTorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading Required Library."
      ],
      "metadata": {
        "id": "_QO-TuabAXTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "rr1UFJVD_x4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preparing MNIST dataset:\n",
        "We are are going to prepare dataloaders for MNIST training and testing set. "
      ],
      "metadata": {
        "id": "rqIbB5x8AihR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the data to torch tensors and normalize it \n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "\t\t\t\t\t\t\t\ttransforms.Normalize((0.1307), ((0.3081)))])\n",
        "\n",
        "# Prepare training set and testing set\n",
        "trainset = torchvision.datasets.MNIST('mnist', train=True, \n",
        "\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST('mnist', train=False,\n",
        "\t\t\t   download=True, transform=transform)\n",
        "\n",
        "# Prepare training loader and testing loader\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "                                          shuffle=True, num_workers=0)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "\t\t\t\t\t\t\t\t\t\t shuffle=False, num_workers=0) "
      ],
      "metadata": {
        "id": "--k8MPBc_rvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inspecting the dataloaders:\n",
        "Now you are going to explore a bit the dataloaders. In particular, you will compute the shape of the dataset in addition to the minibatch size."
      ],
      "metadata": {
        "id": "h9RRC9zRAruw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the shape of the training set and testing set\n",
        "trainset_shape = trainloader.dataset.train_data.shape\n",
        "testset_shape = testloader.dataset.test_data.shape\n",
        "\n",
        "# Print the computed shapes\n",
        "print(trainset_shape, testset_shape)\n",
        "\n",
        "# Compute the size of the minibatch for training set and testing set\n",
        "trainset_batchsize = trainloader.batch_size\n",
        "testset_batchsize = testloader.batch_size\n",
        "\n",
        "# Print sizes of the minibatch\n",
        "print(trainset_batchsize, testset_batchsize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ux_kKREBYe7",
        "outputId": "2884bb34-b177-409e-9aca-718ca77c9f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n",
            "32 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:62: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:67: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building a neural network "
      ],
      "metadata": {
        "id": "pzr9mAnMBomN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ08j5J_0uM7"
      },
      "outputs": [],
      "source": [
        "# Define the class Net\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):    \n",
        "    \t# Define all the parameters of the net\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28 * 1, 200)\n",
        "        self.fc2 = nn.Linear(200,10)\n",
        "\n",
        "    def forward(self, x):   \n",
        "    \t# Do the forward pass\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a Neural Network:"
      ],
      "metadata": {
        "id": "SYUm-lDyCWNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the Adam optimizer and Cross-Entropy loss function\n",
        "model = Net()   \n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "for batch_idx, data_target in enumerate(trainloader):\n",
        "    data = data_target[0]\n",
        "    target = data_target[1]\n",
        "    data = data.view(-1, 28 * 28*1)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Complete a forward pass\n",
        "    output = model(data)\n",
        "\n",
        "    # Compute the loss, gradients and change the weights\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "cPo7POhN0zOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using the network to make predictions"
      ],
      "metadata": {
        "id": "KcYbSNOeGKey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct, total = 0, 0\n",
        "predictions = []\n",
        "# Set the model in eval mode\n",
        "model.eval()\n",
        "\n",
        "for i, data in enumerate(testloader, 0):\n",
        "    inputs, labels = data\n",
        "    \n",
        "    # Put each image into a vector\n",
        "    inputs = inputs.view(-1, 28*28*1)\n",
        "    \n",
        "    # Do the forward pass and get the predictions\n",
        "    outputs = model(inputs)\n",
        "    _, outputs = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (outputs == labels).sum().item()\n",
        "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfjFPpql_Zox",
        "outputId": "2c0556b6-31ff-4bee-fe2e-24d36924f943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The testing set accuracy of the network is: 94 %\n"
          ]
        }
      ]
    }
  ]
}